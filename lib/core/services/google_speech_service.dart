import 'dart:convert';
import 'package:flutter/foundation.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:http/http.dart' as http;
import 'package:permission_handler/permission_handler.dart';

class GoogleSpeechService {
  static final GoogleSpeechService _instance = GoogleSpeechService._internal();
  factory GoogleSpeechService() => _instance;
  GoogleSpeechService._internal();

  static const String _baseUrl = 'https://speech.googleapis.com/v1/speech:recognize';
  
  bool _isRecording = false;
  bool _isAvailable = false;
  String _lastTranscription = '';

  bool get isRecording => _isRecording;
  bool get isAvailable => _isAvailable;
  String get lastTranscription => _lastTranscription;

  /// Initialise le service Google Speech-to-Text
  Future<bool> initialize() async {
    try {
      // V√©rifier la cl√© API
      final apiKey = dotenv.env['GOOGLE_API_KEY'];
      if (apiKey == null || apiKey.isEmpty) {
        debugPrint('‚ùå Cl√© API Google manquante');
        return false;
      }

      // Demander permission microphone
      final status = await Permission.microphone.request();
      if (status != PermissionStatus.granted) {
        debugPrint('‚ùå Permission microphone refus√©e');
        return false;
      }

      _isAvailable = true;
      debugPrint('‚úÖ Google Speech Service initialis√©');
      return true;
    } catch (e) {
      debugPrint('‚ùå Erreur initialisation Google Speech: $e');
      return false;
    }
  }

  /// Transcrit un fichier audio en utilisant l'API Google Speech-to-Text
  Future<String?> transcribeAudio({
    required Uint8List audioData,
    String languageCode = 'fr-FR',
    int sampleRateHertz = 16000,
  }) async {
    try {
      final apiKey = dotenv.env['GOOGLE_API_KEY'];
      if (apiKey == null || apiKey.isEmpty) {
        debugPrint('‚ùå Cl√© API Google manquante');
        return null;
      }

      // Encoder l'audio en base64
      final audioBase64 = base64Encode(audioData);

      // Pr√©parer la requ√™te
      final requestBody = {
        'config': {
          'encoding': 'WEBM_OPUS', // Format support√© par les navigateurs/devices
          'sampleRateHertz': sampleRateHertz,
          'languageCode': languageCode,
          'model': 'latest_long', // Mod√®le optimis√© pour les longues transcriptions
          'useEnhanced': true,
          'enableAutomaticPunctuation': true,
          'enableWordTimeOffsets': false,
          'speechContexts': [
            {
              'phrases': [
                'ingr√©dients', 'recette', 'cuisson', 'pr√©paration',
                'grammes', 'kilogrammes', 'cuill√®res', 'tasses',
                'minutes', 'heures', 'four', 'po√™le', 'casserole'
              ],
              'boost': 10.0
            }
          ]
        },
        'audio': {
          'content': audioBase64
        }
      };

      debugPrint('üé§ Envoi √† Google Speech API...');

      final response = await http.post(
        Uri.parse('$_baseUrl?key=$apiKey'),
        headers: {
          'Content-Type': 'application/json',
        },
        body: jsonEncode(requestBody),
      );

      if (response.statusCode == 200) {
        final responseData = jsonDecode(response.body);
        
        if (responseData['results'] != null && 
            responseData['results'].isNotEmpty) {
          
          final alternatives = responseData['results'][0]['alternatives'];
          if (alternatives != null && alternatives.isNotEmpty) {
            final transcription = alternatives[0]['transcript'] as String;
            final confidence = alternatives[0]['confidence'] as double? ?? 0.0;
            
            debugPrint('‚úÖ Transcription (confiance: ${(confidence * 100).toStringAsFixed(1)}%): $transcription');
            
            _lastTranscription = transcription;
            return transcription;
          }
        }
        
        debugPrint('‚ö†Ô∏è Aucune transcription trouv√©e dans la r√©ponse');
        return null;
      } else {
        debugPrint('‚ùå Erreur API Google Speech: ${response.statusCode}');
        debugPrint('Response: ${response.body}');
        return null;
      }
    } catch (e) {
      debugPrint('‚ùå Exception lors de la transcription: $e');
      return null;
    }
  }

  /// D√©marre l'enregistrement (placeholder - n√©cessite int√©gration native)
  Future<void> startRecording({
    required Function(String) onResult,
    required Function(String) onPartialResult,
    Duration timeout = const Duration(minutes: 1),
  }) async {
    if (!_isAvailable) {
      debugPrint('‚ùå Google Speech Service non disponible');
      return;
    }

    _isRecording = true;
    debugPrint('üé§ Enregistrement d√©marr√© (simulation)');
    
    // Note: Dans une impl√©mentation compl√®te, vous devriez:
    // 1. D√©marrer l'enregistrement audio natif
    // 2. Capturer l'audio en chunks
    // 3. Envoyer p√©riodiquement √† l'API Google pour transcription en temps r√©el
    
    onPartialResult('D√©marrage de l\'enregistrement...');
  }

  /// Arr√™te l'enregistrement
  Future<void> stopRecording() async {
    if (_isRecording) {
      _isRecording = false;
      debugPrint('üé§ Enregistrement arr√™t√©');
    }
  }

  /// Annule l'enregistrement
  Future<void> cancelRecording() async {
    if (_isRecording) {
      _isRecording = false;
      _lastTranscription = '';
      debugPrint('üé§ Enregistrement annul√©');
    }
  }

  /// Test avec un exemple de transcription
  Future<String?> testTranscription() async {
    try {
      debugPrint('üß™ Test de l\'API Google Speech...');
      
      // Valider la cl√© API
      final apiKey = dotenv.env['GOOGLE_API_KEY'];
      if (apiKey == null || apiKey.isEmpty) {
        return 'Erreur: Cl√© API Google manquante dans .env';
      }

      if (apiKey.length < 10) {
        return 'Erreur: Cl√© API Google invalide (trop courte)';
      }

      return 'API Google configur√©e avec succ√®s. Cl√©: ${apiKey.substring(0, 10)}***';
    } catch (e) {
      return 'Erreur test: $e';
    }
  }

  /// Nettoie les ressources
  void dispose() {
    if (_isRecording) {
      stopRecording();
    }
  }
}

/// Extension pour int√©grer facilement avec l'UI existante
extension GoogleSpeechIntegration on GoogleSpeechService {
  /// M√©thode compatible avec l'interface SpeechToTextService existante
  Future<void> startListening({
    required Function(String) onResult,
    required Function(String) onPartialResult,
    Duration timeout = const Duration(minutes: 1),
  }) async {
    await startRecording(
      onResult: onResult,
      onPartialResult: onPartialResult,
      timeout: timeout,
    );
  }

  bool get isListening => _isRecording;
  String get lastWords => _lastTranscription;
}
